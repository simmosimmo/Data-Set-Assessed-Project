---
title: "MAS 61006"
author: "Connor Simmons"
date: "April 2024"
output:
  pdf_document: default
  html_document: default
  fig_caption: yes
fontsize: 11pt
geometry: margin = 1in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(mice)
library(lattice)
library(knitr)
library(tidyverse)
library(miceadds)

# plotting packages
theme_set(theme_bw())
library(RColorBrewer) 
library(viridis)
library(tidybayes)
library(modelr)
library(gridExtra)
library(cowplot)
library(gridExtra)
library(png)

set.seed(321)
```

For this project I chose to look at the [Heart Attack Data Set](https://www.kaggle.com/datasets/sukhmandeepsinghbrar/heart-attack-dataset).

```{r study data, include = FALSE}

Heart_att <- read_csv("https://raw.githubusercontent.com/simmosimmo/Data-Set/main/Medicaldataset.csv")

colnames(Heart_att) <- c("age", "gender", "heart_rate", "SBP", "DBP", "BS", "CK_MB", "troponin", "result")

Heart_att$BS <- ifelse(Heart_att$BS > 120, 1,0)
Heart_att$result <- ifelse(Heart_att$result == "positive",1,0)

#Heart_attnew <- Heart_att[-c(201:1319),]

Heart_att$gender <- as.factor(Heart_att$gender)
Heart_att$BS <- as.factor(Heart_att$BS)
Heart_att$result <- as.factor(Heart_att$result)

```
## The Data

|       **Variables**      	|                                      **Description**                                     	|  **Type**  	|
|:------------------------:	|:----------------------------------------------------------------------------------------:	|:----------:	|
|            Age           	|                            The age of the patients (in years)                            	| Continuous 	|
|          Gender          	|                                   Male = 1, Female = 0                                   	|   Binary   	|
|        Heart Rate (HR)    	|                     The Heart Rate of patients (in beats per minute)                     	| Continuous 	|
|  Systolic Blood Pressure (SBP)	|  The amount of blood pressure experienced be the arteries while the heat is **beating**  	| Continuous 	|
| Diastolic Blood Pressure (DBP)	| The amount of pressure in the arteries while the heart is **resting** between heartbeats 	| Continuous 	|
|   Blood Sugar (BS)  	|                1 indicates glucose levels greater than 120 and 0 otherwise               	|   Binary   	|
|           CK-MB (C)         	|                                  A cardiac enzyme marker*                                 	| Continuous 	|
|         Troponin         	|                               Another cardiac enzyme marker*                              	| Continuous 	|
|          Result          	|           1 represents a positive heart attack and 0 indicates no heart attack           	|   Binary   	|

Figure 1: A list of all the variables included in the data set along with their description. *High levels of an enzyme marker can be the sign of a heart attack or another heart problem.

## The Model

I will fit a logistic regression model to my data as I want to see how the chance of having a heart attack is affected by the other covariates. Therefore, 'result' will be my depedent variable.

My binary outcome will be modelled as a Bernoulli response,    $Y_i \sim Bernoulli(\mu_i)$
Where the probability of having a heart attack is given by the covariates as:
  
$$\mu_i = P(Y_i=1) = \frac{e^{\sum_{j=1}^{m}\beta_iX_{ij}}}{1 + e^{\sum_{j=1}^{m}\beta_iX_{ij}}}$$
  
In which $\mu$ is constrained between 0 and 1. I have applied a logit transformation to $\mu$.

The regression model is:   
  
$$logit(\mu_i) =  \beta_{age}X_{age} + \beta_{gender} + \beta_{HR}X_{HR} + \beta_{SBP}X_{SBP}  + \beta_{BS}X_{BS} + \epsilon$$
Where $\epsilon \sim N(0,\sigma^2)$

I removed troponin and CK-MB from my model as they are known indicators for heart attacks and I am more interested in the impact of the other explanatory variables. Furthermore, in order to avoid issues with collinearity, Diastolic Blood pressure was also removed as it was correlated with Systolic Blood pressure .


```{r, include = FALSE}

#Create some missing data points (probability of missing = 5%). Using the mechanism for producing "NA"s ensures that our values are missing completely at random (MCAR) which implies missing at random (MAR)

makeMissing <- function(mydf, probMissing){
  
  # mydf: your data frame
  # probMissing: the probability that any single
  #  element of the data frame will be changed to NA
  
  R <- matrix(rbinom(nrow(mydf) * ncol(mydf),
                     1,
                     probMissing),
              nrow = nrow(mydf),
              ncol = ncol(mydf))
  mydf[R == 1] <- NA
  mydf
}

```


```{r, include = FALSE}

# Another data frame with missing data points (probability of missing = 30% and 40%)

missing_Heart_att5 <- makeMissing(Heart_att,0.05)

missing_Heart_att10 <- makeMissing(Heart_att,0.1)

missing_Heart_att30 <- makeMissing(Heart_att,0.3)

```

```{r, include = FALSE}

summary(missing_Heart_att5)

```
## Exploratory Data Analysis 

```{r, echo=FALSE, warning= FALSE}


plot1 <- ggplot(missing_Heart_att5, aes(x = age)) +
  geom_histogram(binwidth = 1) +
  labs(x = "Age", y = "Count")

plot2 <- ggplot(missing_Heart_att5, aes(x = heart_rate)) +
  geom_histogram(bins = 20) +
  labs(x = "Heart Rate (beats/minute)", y = "Count")

plot3 <- ggplot(missing_Heart_att5, aes(x = SBP)) +
  geom_histogram(bins = 50) +
  labs(x = "Systalic BP (mmHg)", y = "Count")

plot4 <- ggplot(missing_Heart_att5, aes(x = DBP)) +
  geom_histogram(bins = 50) +
  labs(x = "Diastolic BP", y = "Count")

plot5 <- ggplot(missing_Heart_att5, aes(x = CK_MB)) +
  geom_histogram(binwidth = 5) +
  labs(x = "CK_MB", y = "Count")

plot6 <- ggplot(missing_Heart_att5, aes(x = troponin)) +
  geom_histogram(bins = 30) +
  labs(x = "Troponin", y = "Count")

grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, ncol=3, nrow = 2)

```
Figure 2: Histograms showing the distributions of data within the Heart Attack data set. People over 50 feature more often than younger people and there is an outlier in the Heart Rate data.

The data shows values centred at about 60 years old, which makes sense as older people are more susceptible to heart attacks than younger people. I will check later on to see if the mice algorithm has imputed sensible values.

  
The following plot checks for collinearity between the variables on the heart attack data frame (with 5% of the data missing). The other data frames with larger amounts of missing data showed the same relationships between the variables so I have not included those plots.

```{r, echo=FALSE}

pairs(missing_Heart_att5[,c(1:8)], )


```
Figure 3: Scatterplot pairs of the variables with missing observations in the Heart Attack dataset



```{r, include= FALSE}
pairs(missing_Heart_att10[,c(1:8)])

pairs(missing_Heart_att30[,c(1:8)])

```




```{r, include = FALSE}
#The only sign of correlation is between Systolic and Diastolic blood pressure. Historically systolic #blood pressure and diastolic blood pressure frequently show a linear relationship. Therefore, I have #removed the Diastolic Blood Pressure to avoid issues with collinearity.

ggplot(data = Heart_att, aes(SBP,DBP)) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x) +
  labs(x = "Systolic Blood Pressure", 
       y = "Diastolic Blood Pressure") +
  theme(plot.margin = margin(2,2,2,2, "cm")
        )

```

## The Method

In this report, I will investigate how well certain methods within the mice imputation process cope with increasing proportions of missing data (from 20%, to 30%, to 40%). I will do this in the following way:


* Fit the baseline logistic regression model (shown above) to the data set before any missing data is introduced. Then obtain confidence intervals for each parameter estimate using values given in the R output (in particular the parameter estimate itself and the standard error associated with it).
* Create three iterations of the heart attack data set with differing proportions of missing data. In this case: 5%, 10% and 30% is used.
* Fit the same model to these three data sets and obtain confidence intervals for each parameter. This is known as *complete case analysis* as the model will only use complete rows of data within the data set and ignore rows with any missing data.
* Use the MICE package to impute values for the missing data. Consider using different imputation methods within the mice package (in this report, .... and ..... is used)
* Refit the model to the imputed data sets and obtain confidence intervals
* Compare the confidence intervals from the complete case analysis and from the imputed data sets for each parameter estimate to see how close they are to the baseline model




```{r, include = FALSE}
# Parameter estimates from original data set (no missing data)

original_glm <- glm(result ~ age + gender + SBP + BS + heart_rate, family = binomial, data = Heart_att)
summary_model1 <- summary(original_glm)

#find confidence interval. This is the perfect model. No missing data.
#compare the confidence interval from different models with permuting

#ask what is the best way to compare the models

confint(original_glm)

parameters_model1 <- c(-1.8769073, 0.0398479, 0.5415677, -0.0022379, 0.0143115, 0.0007033)
lower_ci_model1 <- c(-2.687124112, 0.031062780, 0.298942566, -0.006649361, -0.216254596, -0.001551641)
upper_ci_model1 <- c(-1.081941230, 0.048843841, 0.785158694, 0.002176424, 0.245108814, 0.003450778)


```




```{r, include=FALSE}
#Logistic model with missingness 5%

complete_glm <- glm(result ~ age + gender + SBP +  BS + heart_rate, family = binomial, data = missing_Heart_att5)
summary(complete_glm)
confint(complete_glm)

parameters_model2 <- c(-1.4696331, 0.0382094, 0.6061083, -0.0039961, -0.0152088, -0.0009236)
lower_ci_model2 <- c(-2.620447989, 0.028051305, 0.321147322, -0.009158114, -0.288566979, -0.010089103)
upper_ci_model2 <- c(-0.333458359, 0.048640564, 0.892655733, 0.001151271, 0.258139451, 0.008324127)

```



```{r,include=FALSE}

#Logistic Model with missingness 10%

complete_glm10 <- glm(result ~ age + gender + SBP + BS + heart_rate, family = binomial, data = missing_Heart_att10)
summary(complete_glm10)
confint(complete_glm10)

parameters_model3 <- c(-1.7100183, 0.0365985, 0.5545984, -0.0020759, -0.0953744, 0.0006471)
lower_ci_model3 <- c(-2.805298136, 0.024735392, 0.231390474, -0.007973483, -0.405507694, -0.001640619)
upper_ci_model3 <- c(-0.638771020, 0.048827983, 0.879542804, 0.003829913, 0.214756011, 0.003452157)

```



```{r,include=FALSE}

#Logistic Model with missingness 30%

complete_glm30 <- glm(result ~ age + gender + SBP + BS + heart_rate, family = binomial, data = missing_Heart_att30)
summary(complete_glm30)
confint(complete_glm30)

parameters_model4 <- c(-1.545378, 0.026866, 0.658712, 0.004735, -0.099214, -0.002219)
lower_ci_model4 <- c(-4.398390402, 0.003183184, -0.068479752, -0.008256708, -0.777585618, -0.022738740)
upper_ci_model4 <- c(1.21269477, 0.05152126, 1.39029203, 0.01826850, 0.58062253, 0.01875686)


```

## Convergence of the MICE Algorithm

It is important to check that the imputation process has reasonably converged to a stable solution. Without convergence, the imputed values may change significantly between iterations which indicates that the values are not reliable or accurate representations of the missing data.

```{r, include= FALSE}

heart.imp <- mice(missing_Heart_att5, Print = F)

```


```{r, include=FALSE}
plot(heart.imp)
```


```{r, echo = FALSE, fig.show = "asis"}
heart.imp.long <- mice.mids(heart.imp, maxit = 20, print = F)

plot(heart.imp.long, layout = c(3,6)) 


```





Figure 4: Convergence diagnostics for MICE algorithm on the heart attack data set, with default of 5 imputations, each for 25 iterations.

Initially, I ran the mice algorithm with only 5 iterations and the values of SDP and BS hardly mixed which suggested non-convergence. In order to improve the imputation, the algorithm was run for a further 20 iterations. As shown in figure 4, the streams mix nicely and they have stabilised which suggests convergence.


```{r, include = FALSE}

#Ensuring convergence of imputations with more missing data.

#For 10%
heart.imp10 <- mice(missing_Heart_att10, Print = F)

plot(heart.imp10)

heart.imp.long10 <- mice.mids(heart.imp10, maxit = 30, print = F)

plot(heart.imp.long10) 

#For 30%

heart.imp30 <- mice(missing_Heart_att30, Print = F)

plot(heart.imp30)

heart.imp.long30 <- mice.mids(heart.imp30, maxit = 30, print = F)

plot(heart.imp.long30) 

```



As you might expect, the data imputation with 15 and 30 percent missing information took more iterations to converge. In my case, they both needed 35 iterations to stabilise. 

```{r, include = FALSE}
#Fit and pool the data from the multiple data frames

heart_fit <- with(heart.imp.long, glm(result ~ age + gender + SBP +  BS + heart_rate, family = "binomial"))

(heart_fit_pool <- pool(heart_fit))

summary(heart_fit_pool)

coefficients <- summary(heart_fit_pool, conf.int = TRUE)

#20% missing data - no method with within mice specified

parameters_model5 <- c(-1.790825660, 0.039623893, 0.579634831, -0.003656099, 0.035236940, 0.001690176)
lower_ci_model5 <- c(-2.643182733, 0.030422943,  0.321453123, -0.008146513, -0.215621748, -0.002761726)
upper_ci_model5 <- c(-0.9384685871, 0.0488248432, 0.8378165395, 0.0008343147, 0.2860956276, 0.0061420791)


```



```{r, include = FALSE}

#Experiment with at least two of the built-in imputation methods in the mice package. First, using the Unconditional mean imputation method (Method = "rf")

norm_pred_heart_imp <- mice(missing_Heart_att5, method = c("mean", "logreg.boot", "mean", "mean","mean","logreg.boot","mean", "mean","logreg.boot") , m = 5, maxit = 20, print = F)

norm_pred_heart_fit <- with(norm_pred_heart_imp, glm(result ~ age + gender + SBP +  BS +  heart_rate, family = "binomial"))

norm_pred_fit_pool <- pool(norm_pred_heart_fit)


coefficients2 <- summary(norm_pred_fit_pool, conf.int = TRUE, conf.level = 0.95)

parameters_model6 <- c(-1.866784502, 0.039183061, 0.504972419, -0.002922608,  0.046547045, 0.002265476)
lower_ci_model6 <- c(-2.807249666, 0.029940920, 0.252801162, -0.007473551, -0.190399964, -0.004027093)
upper_ci_model6 <- c(-0.926319338, 0.048425201, 0.757143675, 0.001628335, 0.283494053, 0.008558046)


```


```{r, include=FALSE}

#Next, using the Bayesian Linear regression (method = "rf")

norm_heart_imp <- mice(missing_Heart_att5, method = "rf", m = 5, maxit = 20, print = F)

norm_heart_fit <- with(norm_heart_imp, glm(result ~ age + gender + SBP  + BS +  heart_rate,family = "binomial"))

(norm_fit_pool <- pool(norm_heart_fit))

coefficients3 <- summary(norm_fit_pool, conf.int = TRUE)

parameters_model7 <- c(-1.8506931666, 0.0410138422, 0.5738058198, -0.0031349060, 0.0301815185, 0.0005767591)
lower_ci_model7 <- c(-2.725751914, 0.031158667, 0.328204500, -0.007780425, -0.207019024, -0.002328829)
upper_ci_model7 <- c(-0.975634420, 0.050869017, 0.819407140, 0.001510613, 0.267382061, 0.003482347)


```



```{r, include=FALSE}

#30% missing data

heart.imp30 <- mice(missing_Heart_att30, Print = F)
heart.imp.long30 <- mice.mids(heart.imp30, maxit = 35, print = F)

heart_fit30 <- with(heart.imp.long30, glm(result ~ age + gender + SBP +  BS + heart_rate, family = "binomial"))

(heart_fit_pool30 <- pool(heart_fit30))

coefficients4 <- summary(heart_fit_pool30)



```

## Results


```{r, echo=FALSE, fig.show = "hold"}
#plotting complete case anaylsis with different amounts of missing data


data_model1 <- data.frame(Parameter = factor(1:length(parameters_model1)),
                          Estimate = parameters_model1,
                          Lower_CI = lower_ci_model1,
                          Upper_CI = upper_ci_model1,
                          Model = "Baseline Model")


data_model2 <- data.frame(Parameter = factor(1:length(parameters_model2)),
                          Estimate = parameters_model2,
                          Lower_CI = lower_ci_model2,
                          Upper_CI = upper_ci_model2,
                          Model = "Complete Case (5% missing data)")

data_model3 <- data.frame(Parameter = factor(1:length(parameters_model3)),
                          Estimate = parameters_model3,
                          Lower_CI = lower_ci_model3,
                          Upper_CI = upper_ci_model3,
                          Model = "Complete Case (10% missing data)")

data_model4 <- data.frame(Parameter = factor(1:length(parameters_model4)),
                          Estimate = parameters_model4,
                          Lower_CI = lower_ci_model4,
                          Upper_CI = upper_ci_model4,
                          Model = "Complete Case (30% missing data)")

data_model5 <- data.frame(Parameter = factor(1:length(parameters_model5)),
                          Estimate = parameters_model5,
                          Lower_CI = lower_ci_model5,
                          Upper_CI = upper_ci_model5,
                          Model = "Imputed Model")

data_model5.1 <- data.frame(Parameter = factor(1:length(parameters_model5)),
                          Estimate = parameters_model5,
                          Lower_CI = lower_ci_model5,
                          Upper_CI = upper_ci_model5,
                          Model = "Method = Default Method")

data_model6 <- data.frame(Parameter = factor(1:length(parameters_model6)),
                          Estimate = parameters_model6,
                          Lower_CI = lower_ci_model6,
                          Upper_CI = upper_ci_model6,
                          Model = "Method = mean and logreg.boot")

data_model7 <- data.frame(Parameter = factor(1:length(parameters_model7)),
                          Estimate = parameters_model7,
                          Lower_CI = lower_ci_model7,
                          Upper_CI = upper_ci_model7,
                          Model = "Method = rf")

combined_data <- rbind(data_model1, data_model2, data_model3, data_model4)


# ggplot(combined_data, aes(x = Parameter, y = Estimate, color = Model)) +
#  geom_point(position = position_dodge(width = 0.5)) +
#  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI),
#                position = position_dodge(width = 0.5), width = 0.2) +
#  labs(x = "Parameter", y = "Estimate", title = "Parameter Estimates Comparison", 
#  caption = "Figure : The confidence intervals for the different parameter 
#  estimates tends to increase when more missing data is introduced.") +
#  scale_x_discrete(labels = c("Intercept", "Age", "Gender", "Systolic BP", "Diastolic BP", "Blood  #Sugar", "Heart Rate")) +  
#  theme_minimal() +
#  theme(axis.text.x = element_text(angle = 45, hjust = 1),plot.caption = element_text(hjust = 0)) 

# comparing the parameter estimates of the baseline model and the complete case analysis with the imputed data for 20%

combined_data2 <- rbind(data_model1[c(1,3,5),], data_model2[c(1,3,5),], data_model5[c(1,3,5),])

#caption = "Figure : The confidence intervals for parameter estimates. The confidence interval of the imputed data for gender and intercept are outside of the 95% confidence interval for the baseline model."

results_plot_1 <- ggplot(combined_data2, aes(x = Parameter, y = Estimate, color = Model)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI),
                position = position_dodge(width = 0.5), width = 0.2) +
  labs(x = "Parameter", y = "Estimate", title = "Parameter Estimates Comparison") +
  scale_x_discrete(labels = c("intercept" , "Gender","Blood Sugar")) +  
  theme_minimal() 


combined_data3 <- rbind(data_model1[c(2,4,6),], data_model2[c(2,4,6),], data_model5[c(2,4,6),])


results_plot_2 <- ggplot(combined_data3, aes(x = Parameter, y = Estimate, color = Model)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI),
                position = position_dodge(width = 0.5), width = 0.2) +
  labs(y = "Estimate", x = "", 
  caption = "Figure 5: Removing intercept, gender and blood sugar gives a closer look at the parameter estimates. The 
  confidence interval of the imputed data for age is outside of the 95% confidence interval 
  for the baseline model.") +
  scale_x_discrete(labels = c("Age", "Systolic BP", "Heart Rate")) +  
  theme_minimal() +
  theme(plot.caption = element_text(hjust = 0), legend.position = "none") 

grid.arrange(results_plot_1,results_plot_2)


```

As you can see from Figure 5, the confidence intervals of the baseline model and the imputed model do not overlap for the either the gender, age or the intercept. On the other hand, all of the other covariates from the imputed model are within the 95% confidence interval from the baseline model. The MICE imputation process has created values which are closer to the real dataset for those variables whose parameter estimates are within the confidence interval of the baseline model.

Talk about how the standard errors and parameter estimates change across the different models.

```{r, echo = FALSE}
combined_data4 <- rbind(data_model1[c(1,3,5),],data_model5.1[c(1,3,5),], data_model6[c(1,3,5),], data_model7[c(1,3,5),])


results_plot_1 <- ggplot(combined_data4, aes(x = Parameter, y = Estimate, color = Model)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI),
                position = position_dodge(width = 0.5), width = 0.2) +
  labs(x = "Parameter", y = "Estimate", title = "Comparing Different Imputation Methods") +
  scale_x_discrete(labels = c("intercept" , "Gender","Blood Sugar")) +  
  theme_minimal() 


combined_data4.1 <- rbind(data_model1[c(2,4,6),],data_model5.1[c(2,4,6),], data_model6[c(2,4,6),], data_model7[c(2,4,6),])


results_plot_2 <- ggplot(combined_data4.1, aes(x = Parameter, y = Estimate, color = Model)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI),
                position = position_dodge(width = 0.5), width = 0.2) +
  labs(y = "Estimate", x = "", 
  caption = "Figure 6: The different imputation methods provide consistent results. 
  However, the results are not accurate for the estimate or the age variable.") +
  scale_x_discrete(labels = c("Age", "Systolic BP", "Heart Rate")) +  
  theme_minimal() +
  theme(plot.caption = element_text(hjust = 0), legend.position = "none") 

grid.arrange(results_plot_1,results_plot_2)


```
The different imputation methods within MICE vary in precision, with the mean method being the most consistent for each parameter. 

## Conclusion




```{r, include= FALSE}
model_variables <- c("Intercept", "age", "gender", "Systolic Blood Pressure", "Diastolic Blood Pressure", "Blood Sugar", "Troponin")
orig_parameter_estfinal <- c(66.143118,-0.099951,-3.01814,-0.154927,0.563665,-0.009793,0.555504)
orig_se <- c(10.633614,0.104552,3.002963,0.066863,0.124467,0.018887,1.233687)
orig_df <- data.frame(model_variables, orig_parameter_estfinal, orig_se)
kable(orig_df, "pipe", col.names = c("Explantory Variables","Parameter Estimates", "Standard Errors"), align = c("l","c","c"), caption = "Original Parameter Estimates (No Missing Data)")

comp_parameter_est <- c(74.47066, -0.72205, -3.53930, -0.27656, 1.27797, -0.04754, 1.20874)
comp_se <- c(38.29022, 0.40502, 11.54357, 0.26742, 0.49104, 0.07194, 4.45535)
comp_df <- data.frame(model_variables, comp_parameter_est, comp_se)
kable(comp_df, "pipe", col.names = c("Explantory Variables","Parameter Estimates", "Standard Errors"), align = c("l","c","c"), caption = "Complete Case Anaylsis (Modified Data Set)")

mice_parameter_est <- c(59.55579385,-0.11712960,-2.25589235,-0.15508631,0.67222651,-0.01129411,1.85900469)
mice_se <- c(2.614747e+02, 2.215104e-02,1.360201e+01,1.170735e-02,1.090501e-01,5.421176e-04, 1.383770e+01)
mice_df <- data.frame(model_variables, mice_parameter_est, mice_se)
kable(mice_df, "pipe", col.names = c("Explantory Variables","Parameter Estimates", "Standard Errors"), align = c("l","c","c"), caption = "Multiple Imputation with MICE (Modified Data Set)")



```


## References


[1]: Stef van Buuren, Karin Groothuis-Oudshoorn (2011). mice: Multivariate Imputation by Chained
  Equations in R. Journal of Statistical Software, 45(3), 1-67. DOI 10.18637/jss.v045.i03.




